{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f04f072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09dc06e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3778</th>\n",
       "      <td>3779</td>\n",
       "      <td>15658486</td>\n",
       "      <td>Gidney</td>\n",
       "      <td>579</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>148021.12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74878.22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>2398</td>\n",
       "      <td>15747724</td>\n",
       "      <td>Briggs</td>\n",
       "      <td>671</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>23235.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7677</th>\n",
       "      <td>7678</td>\n",
       "      <td>15711977</td>\n",
       "      <td>Finch</td>\n",
       "      <td>695</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>161533.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100940.91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308</th>\n",
       "      <td>9309</td>\n",
       "      <td>15728683</td>\n",
       "      <td>Lombardo</td>\n",
       "      <td>742</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>131534.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8821</th>\n",
       "      <td>8822</td>\n",
       "      <td>15619953</td>\n",
       "      <td>Efremov</td>\n",
       "      <td>662</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>6</td>\n",
       "      <td>105021.28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>48242.38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6040</th>\n",
       "      <td>6041</td>\n",
       "      <td>15735358</td>\n",
       "      <td>Dowse</td>\n",
       "      <td>682</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4654.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "3778       3779    15658486    Gidney          579     Spain  Female   59   \n",
       "2397       2398    15747724    Briggs          671     Spain  Female   34   \n",
       "7677       7678    15711977     Finch          695    France    Male   36   \n",
       "9308       9309    15728683  Lombardo          742    France    Male   27   \n",
       "8821       8822    15619953   Efremov          662     Spain  Female   42   \n",
       "6040       6041    15735358     Dowse          682     Spain    Male   46   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "3778       3  148021.12              1          1               1   \n",
       "2397      10       0.00              1          1               0   \n",
       "7677       4  161533.00              1          1               0   \n",
       "9308       0       0.00              2          0               1   \n",
       "8821       6  105021.28              1          1               0   \n",
       "6040       4       0.00              1          1               1   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "3778         74878.22       0  \n",
       "2397         23235.38       0  \n",
       "7677        100940.91       0  \n",
       "9308        131534.96       0  \n",
       "8821         48242.38       0  \n",
       "6040          4654.28       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(r\"C:\\Users\\Usman\\Downloads\\churn\\Churn_Modelling.csv\")\n",
    "df.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcdd3171",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=[\"RowNumber\",\"CustomerId\",\"Surname\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8acbd695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7685</th>\n",
       "      <td>705</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>92889.91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>109496.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285</th>\n",
       "      <td>735</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>9</td>\n",
       "      <td>98807.45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>184570.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6327</th>\n",
       "      <td>667</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>121542.57</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>186841.71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>432</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>110219.14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43046.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>727</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47468.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "7685          705   Germany  Female   40       3   92889.91              1   \n",
       "3285          735   Germany  Female   43       9   98807.45              1   \n",
       "6327          667     Spain  Female   36       3  121542.57              2   \n",
       "2856          432   Germany  Female   45       3  110219.14              1   \n",
       "8731          727     Spain  Female   41      10       0.00              2   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  \n",
       "7685          1               1        109496.69       0  \n",
       "3285          0               0        184570.04       1  \n",
       "6327          1               1        186841.71       0  \n",
       "2856          1               0         43046.70       1  \n",
       "8731          0               1         47468.56       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e74c3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreditScore          int64\n",
       "Geography           object\n",
       "Gender              object\n",
       "Age                  int64\n",
       "Tenure               int64\n",
       "Balance            float64\n",
       "NumOfProducts        int64\n",
       "HasCrCard            int64\n",
       "IsActiveMember       int64\n",
       "EstimatedSalary    float64\n",
       "Exited               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "633a9287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"IsActiveMember\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e237e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.get_dummies(df,columns=[\"Geography\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0902c9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619  Female   42       2       0.00              1          1   \n",
       "1             608  Female   41       1   83807.86              1          0   \n",
       "2             502  Female   42       8  159660.80              3          1   \n",
       "3             699  Female   39       1       0.00              2          0   \n",
       "4             850  Female   43       2  125510.82              1          1   \n",
       "...           ...     ...  ...     ...        ...            ...        ...   \n",
       "9995          771    Male   39       5       0.00              2          1   \n",
       "9996          516    Male   35      10   57369.61              1          1   \n",
       "9997          709  Female   36       7       0.00              1          0   \n",
       "9998          772    Male   42       3   75075.31              2          1   \n",
       "9999          792  Female   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "0                  1        101348.88       1                 1   \n",
       "1                  1        112542.58       0                 0   \n",
       "2                  0        113931.57       1                 1   \n",
       "3                  0         93826.63       0                 1   \n",
       "4                  1         79084.10       0                 0   \n",
       "...              ...              ...     ...               ...   \n",
       "9995               0         96270.64       0                 1   \n",
       "9996               1        101699.77       0                 1   \n",
       "9997               1         42085.58       1                 1   \n",
       "9998               0         92888.52       1                 0   \n",
       "9999               0         38190.78       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "0                     0                0  \n",
       "1                     0                1  \n",
       "2                     0                0  \n",
       "3                     0                0  \n",
       "4                     0                1  \n",
       "...                 ...              ...  \n",
       "9995                  0                0  \n",
       "9996                  0                0  \n",
       "9997                  0                0  \n",
       "9998                  1                0  \n",
       "9999                  0                0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "373f9da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Gender\"].replace({\"Female\":0,\"Male\":1},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13f59ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6330</th>\n",
       "      <td>744</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10662.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6879</th>\n",
       "      <td>665</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>90920.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112256.57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5852</th>\n",
       "      <td>544</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>66483.32</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>110317.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>698</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>121263.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13387.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3148</th>\n",
       "      <td>648</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>130694.89</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>153955.38</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "6330          744       0   39       6       0.00              1          0   \n",
       "6879          665       1   25       7   90920.75              1          0   \n",
       "5852          544       1   22       3   66483.32              1          0   \n",
       "3258          698       0   36       7  121263.62              1          1   \n",
       "3148          648       0   39       6  130694.89              2          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "6330               0         10662.58       0                 1   \n",
       "6879               1        112256.57       0                 1   \n",
       "5852               1        110317.39       0                 0   \n",
       "3258               1         13387.88       0                 0   \n",
       "3148               1        153955.38       1                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "6330                  0                0  \n",
       "6879                  0                0  \n",
       "5852                  0                1  \n",
       "3258                  1                0  \n",
       "3148                  0                0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cae46a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6ad56a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"CreditScore\",\"Balance\",\"EstimatedSalary\"]]=scaler.fit_transform(df[[\"CreditScore\",\"Balance\",\"EstimatedSalary\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8ac9108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8091</th>\n",
       "      <td>0.836</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>0.382564</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.368411</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5505</th>\n",
       "      <td>0.368</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.403076</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5427</th>\n",
       "      <td>0.498</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>0.513994</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.201553</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8425</th>\n",
       "      <td>0.810</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>0.466468</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109263</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "8091        0.836       1   29       2  0.382564              2          1   \n",
       "5505        0.368       0   53       7  0.000000              2          1   \n",
       "5427        0.498       1   36       3  0.513994              2          1   \n",
       "8425        0.810       1   29       9  0.466468              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Exited  Geography_France  \\\n",
       "8091               1         0.368411       0                 1   \n",
       "5505               1         0.403076       0                 1   \n",
       "5427               1         0.201553       0                 0   \n",
       "8425               1         0.109263       0                 1   \n",
       "\n",
       "      Geography_Germany  Geography_Spain  \n",
       "8091                  0                0  \n",
       "5505                  0                0  \n",
       "5427                  1                0  \n",
       "8425                  0                0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96b4b6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53185f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(\"Exited\",axis=1)\n",
    "y=df[\"Exited\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c690604",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45496e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27df7a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 13)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dec1b579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "697055b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.Sequential([\n",
    "    keras.layers.Dense(10,input_shape=(12,),activation=\"relu\"),\n",
    "    keras.layers.Dense(8,activation=\"relu\"),\n",
    "    keras.layers.Dense(6,activation=\"relu\"),\n",
    "    keras.layers.Dense(1,activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70975869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5811 - accuracy: 0.7607\n",
      "Epoch 2/6\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5304 - accuracy: 0.7962\n",
      "Epoch 3/6\n",
      "250/250 [==============================] - 1s 2ms/step - loss: 0.5029 - accuracy: 0.7962\n",
      "Epoch 4/6\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.7962\n",
      "Epoch 5/6\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4495 - accuracy: 0.7962\n",
      "Epoch 6/6\n",
      "250/250 [==============================] - 0s 2ms/step - loss: 0.4448 - accuracy: 0.7962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x16bfc72ae50>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96a11da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 2ms/step - loss: 0.4465 - accuracy: 0.7965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4465085566043854, 0.796500027179718]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19e83ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6df9b48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.15872738],\n",
       "       [0.09498125],\n",
       "       [0.41486657],\n",
       "       [0.29907233],\n",
       "       [0.13059536]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yp[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4875ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for i in yp:\n",
    "    if i>0.5:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad38b0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b606a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9676    0\n",
       "9915    0\n",
       "7093    1\n",
       "7726    0\n",
       "6246    1\n",
       "2855    0\n",
       "1456    0\n",
       "1746    1\n",
       "2252    0\n",
       "266     0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17b9ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "08b058c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89      1593\n",
      "           1       0.00      0.00      0.00       407\n",
      "\n",
      "    accuracy                           0.80      2000\n",
      "   macro avg       0.40      0.50      0.44      2000\n",
      "weighted avg       0.63      0.80      0.71      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Usman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Usman\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60445a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1593,    0],\n",
       "       [ 407,    0]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f0fc7dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fb649cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=tf.math.confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d92d1bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(69.0, 0.5, 'True')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "sn.heatmap(cm,annot=True,fmt='d')\n",
    "plt.xlabel(\"predicted\")\n",
    "plt.ylabel(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c496e91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4a8992",
   "metadata": {},
   "source": [
    "## Under Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b9286e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_class_0,count_class_1=df.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2e89632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0=df[df[\"Exited\"]==0]\n",
    "df_class_1=df[df[\"Exited\"]==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "68e0d698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_0_under=df_class_0.sample(count_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "228258b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_under=pd.concat([df_class_0_under,df_class_1],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "64f3ab67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Under Sampling\n",
      "Random Under Sampling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2037\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    2037\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Random Under Sampling\")\n",
    "df_test_under.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "715252c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x=df_test_under.drop(\"Exited\",axis=1)\n",
    "y=df_test_under[\"Exited\"]\n",
    "X_train, X_test, y_train, y_test=train_test_split(x,y,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4a8d312b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1630\n",
       "1    1629\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    1630\n",
       "1    1629\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae469ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, y_train, X_test, y_test, loss):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(13, input_dim=12, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "    print(model.evaluate(X_test, y_test))\n",
    "\n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "\n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "\n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "afe378d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.6904 - accuracy: 0.5186\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.6904 - accuracy: 0.5186\n",
      "Epoch 2/100\n",
      "Epoch 2/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6091\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6598 - accuracy: 0.6091\n",
      "Epoch 3/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5496 - accuracy: 0.8750Epoch 3/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.6434\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.6434\n",
      "Epoch 4/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6297 - accuracy: 0.5625Epoch 4/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6628\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.6628\n",
      "Epoch 5/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5471 - accuracy: 0.8125Epoch 5/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6787\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6787\n",
      "Epoch 6/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5657 - accuracy: 0.7812Epoch 6/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6873\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6031 - accuracy: 0.6873\n",
      "Epoch 7/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5015 - accuracy: 0.7812Epoch 7/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.6861\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6036 - accuracy: 0.6861\n",
      "Epoch 8/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5073 - accuracy: 0.7812Epoch 8/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6892\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6002 - accuracy: 0.6892\n",
      "Epoch 9/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7449 - accuracy: 0.5625Epoch 9/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6950\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5958 - accuracy: 0.6950\n",
      "Epoch 10/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5916 - accuracy: 0.6562Epoch 10/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6944\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6944\n",
      "Epoch 11/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7045 - accuracy: 0.5000Epoch 11/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.6953\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.6953\n",
      "Epoch 12/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4985 - accuracy: 0.8125Epoch 12/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.6895\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5956 - accuracy: 0.6895\n",
      "Epoch 13/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5669 - accuracy: 0.6562Epoch 13/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.69500s - loss: 0.5954 - accuracy: 0.6957 - ETA: 0s - loss: 0.5954 - accuracy: 0.69\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6950\n",
      "Epoch 14/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6901 - accuracy: 0.6250Epoch 14/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7005\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5905 - accuracy: 0.7005\n",
      "Epoch 15/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4538 - accuracy: 0.8438Epoch 15/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.7057\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5871 - accuracy: 0.7057\n",
      "Epoch 16/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5981 - accuracy: 0.7188Epoch 16/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.6981\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.6981\n",
      "Epoch 17/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7155 - accuracy: 0.5312Epoch 17/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7008\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.7008\n",
      "Epoch 18/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7223 - accuracy: 0.5938Epoch 18/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.6996\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.6996\n",
      "Epoch 19/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7102 - accuracy: 0.6250Epoch 19/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.6996\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.6996\n",
      "Epoch 20/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6680 - accuracy: 0.5938Epoch 20/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.6996\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.6996\n",
      "Epoch 21/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5646 - accuracy: 0.7188Epoch 21/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7064\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.7064\n",
      "Epoch 22/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6744 - accuracy: 0.7188Epoch 22/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6959\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6959\n",
      "Epoch 23/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4977 - accuracy: 0.7812Epoch 23/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7042\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7042\n",
      "Epoch 24/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6644 - accuracy: 0.6875Epoch 24/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.6993\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.6993\n",
      "Epoch 25/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6992 - accuracy: 0.5938Epoch 25/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.7067\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.7067\n",
      "Epoch 26/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7017 - accuracy: 0.5938Epoch 26/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7027\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.7027\n",
      "Epoch 27/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5941 - accuracy: 0.6875Epoch 27/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7014102 [============>.................] - ETA: 0s - loss: 0.5912 - accura\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7014\n",
      "Epoch 28/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5597 - accuracy: 0.7500Epoch 28/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6950\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5842 - accuracy: 0.6950\n",
      "Epoch 29/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6336 - accuracy: 0.5312Epoch 29/100\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.5894 - accuracy: 0. - 0s 2ms/step - loss: 0.5851 - accuracy: 0.6959\n",
      " - 0s 2ms/step - loss: 0.5851 - accuracy: 0.6959\n",
      "Epoch 30/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5100 - accuracy: 0.8438Epoch 30/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.6935\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.6935\n",
      "Epoch 31/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6254 - accuracy: 0.6875Epoch 31/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7045\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7045\n",
      "Epoch 32/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6679 - accuracy: 0.6250Epoch 32/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7039\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7039\n",
      "Epoch 33/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5192 - accuracy: 0.8438Epoch 33/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.7088\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.7088\n",
      "Epoch 34/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6170 - accuracy: 0.6562Epoch 34/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.70700s - loss: 0.5859 - accuracy: 0.7105 - ETA: 0s - loss: 0.5859 - accuracy: 0.71\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7070\n",
      "Epoch 35/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5012 - accuracy: 0.8125Epoch 35/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.7057\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.7057\n",
      "Epoch 36/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5801 - accuracy: 0.7188Epoch 36/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7106\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7106\n",
      "Epoch 37/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5378 - accuracy: 0.7500Epoch 37/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7097\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7097\n",
      "Epoch 38/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5032 - accuracy: 0.7500Epoch 38/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7039\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7039\n",
      "Epoch 39/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4733 - accuracy: 0.7500Epoch 39/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7054\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5836 - accuracy: 0.7054\n",
      "Epoch 40/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6138 - accuracy: 0.6875Epoch 40/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7021\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.7021\n",
      "Epoch 41/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6213 - accuracy: 0.7188Epoch 41/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7091\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7091\n",
      "Epoch 42/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7157 - accuracy: 0.5938Epoch 42/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7091\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7091\n",
      "Epoch 43/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6148 - accuracy: 0.6562Epoch 43/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7024\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7024\n",
      "Epoch 44/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5622 - accuracy: 0.7188Epoch 44/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.6993\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5826 - accuracy: 0.6993\n",
      "Epoch 45/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4908 - accuracy: 0.7812Epoch 45/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7051\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7051\n",
      "Epoch 46/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6391 - accuracy: 0.6562Epoch 46/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7039\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7039\n",
      "Epoch 47/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5132 - accuracy: 0.7188Epoch 47/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7048\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7048\n",
      "Epoch 48/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5488 - accuracy: 0.6875Epoch 48/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7067\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7067\n",
      "Epoch 49/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5826 - accuracy: 0.6250Epoch 49/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7088\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7088\n",
      "Epoch 50/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5176 - accuracy: 0.7812Epoch 50/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6993\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6993\n",
      "Epoch 51/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6161 - accuracy: 0.6875Epoch 51/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7027\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7027\n",
      "Epoch 52/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7044 - accuracy: 0.5625Epoch 52/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7100\n",
      "Epoch 53/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6063 - accuracy: 0.6875Epoch 53/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7131\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7131\n",
      "Epoch 54/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6128 - accuracy: 0.6562Epoch 54/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.7039\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5800 - accuracy: 0.7039\n",
      "Epoch 55/100\n",
      "  1/102 [..............................] - ETA: 3s - loss: 0.5222 - accuracy: 0.8438Epoch 55/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7076\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7076\n",
      "Epoch 56/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4597 - accuracy: 0.7500Epoch 56/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.7091\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.7091\n",
      "Epoch 57/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6069 - accuracy: 0.7188Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7094\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7094\n",
      "Epoch 58/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4895 - accuracy: 0.7188Epoch 58/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7054\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7054\n",
      "Epoch 59/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5323 - accuracy: 0.7188Epoch 59/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.7100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.7100\n",
      "Epoch 60/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6527 - accuracy: 0.6250Epoch 60/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7088\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7088\n",
      "Epoch 61/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4890 - accuracy: 0.8125Epoch 61/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7033\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5851 - accuracy: 0.7033\n",
      "Epoch 62/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4227 - accuracy: 0.8125Epoch 62/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.6993\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.6993\n",
      "Epoch 63/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4426 - accuracy: 0.9062Epoch 63/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7033\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7033\n",
      "Epoch 64/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6779 - accuracy: 0.5625Epoch 64/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7048\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7048\n",
      "Epoch 65/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5692 - accuracy: 0.7500Epoch 65/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7045\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7045\n",
      "Epoch 66/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5885 - accuracy: 0.7500Epoch 66/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7039\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7039\n",
      "Epoch 67/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7227 - accuracy: 0.5938Epoch 67/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.7070\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.7070\n",
      "Epoch 68/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6169 - accuracy: 0.7188Epoch 68/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7088\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7088\n",
      "Epoch 69/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7062 - accuracy: 0.5000Epoch 69/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7073\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5797 - accuracy: 0.7073\n",
      "Epoch 70/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5191 - accuracy: 0.7812Epoch 70/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7008\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7008\n",
      "Epoch 71/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5929 - accuracy: 0.6875Epoch 71/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7045\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7045\n",
      "Epoch 72/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6583 - accuracy: 0.5938Epoch 72/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.7091\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5813 - accuracy: 0.7091\n",
      "Epoch 73/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4745 - accuracy: 0.7812Epoch 73/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.70760s - loss: 0.5666 - accuracy: 0.7288 - ETA: 0s - loss: 0.5666 - accura\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5798 - accuracy: 0.7076\n",
      "Epoch 74/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6707 - accuracy: 0.7188Epoch 74/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7143\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7143\n",
      "Epoch 75/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5094 - accuracy: 0.7812Epoch 75/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7110\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7110\n",
      "Epoch 76/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5045 - accuracy: 0.7812Epoch 76/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7054\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7054\n",
      "Epoch 77/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5739 - accuracy: 0.7500Epoch 77/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6990\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6990\n",
      "Epoch 78/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6718 - accuracy: 0.5625Epoch 78/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7045\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7045\n",
      "Epoch 79/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5579 - accuracy: 0.7812Epoch 79/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7057\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7057\n",
      "Epoch 80/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6400 - accuracy: 0.7188Epoch 80/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7067\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5784 - accuracy: 0.7067\n",
      "Epoch 81/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6074 - accuracy: 0.5938Epoch 81/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7021\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5799 - accuracy: 0.7021\n",
      "Epoch 82/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7613 - accuracy: 0.5000Epoch 82/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7033\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7033\n",
      "Epoch 83/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4787 - accuracy: 0.8438Epoch 83/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7042\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7042\n",
      "Epoch 84/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6499 - accuracy: 0.6562Epoch 84/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7106\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.7106\n",
      "Epoch 85/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5443 - accuracy: 0.7500Epoch 85/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7076\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7076\n",
      "Epoch 86/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5942 - accuracy: 0.6562Epoch 86/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.6990\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5843 - accuracy: 0.6990\n",
      "Epoch 87/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5115 - accuracy: 0.7812Epoch 87/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7051\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5783 - accuracy: 0.7051\n",
      "Epoch 88/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5882 - accuracy: 0.6875Epoch 88/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7088\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5799 - accuracy: 0.7088\n",
      "Epoch 89/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6529 - accuracy: 0.6562Epoch 89/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7060\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7060\n",
      "Epoch 90/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5299 - accuracy: 0.7500Epoch 90/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7064\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7064\n",
      "Epoch 91/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6214 - accuracy: 0.6562Epoch 91/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7082\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7082\n",
      "Epoch 92/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5383 - accuracy: 0.7500Epoch 92/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.6981\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5796 - accuracy: 0.6981\n",
      "Epoch 93/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6790 - accuracy: 0.6250Epoch 93/100\n",
      "102/102 [==============================] - ETA: 0s - loss: 0.5753 - accuracy: 0. - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7088\n",
      " - 0s 2ms/step - loss: 0.5769 - accuracy: 0.7088\n",
      "Epoch 94/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5660 - accuracy: 0.7500Epoch 94/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7011\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7011\n",
      "Epoch 95/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5701 - accuracy: 0.6562Epoch 95/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.7014\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.7014\n",
      "Epoch 96/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6236 - accuracy: 0.5938Epoch 96/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7024\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5770 - accuracy: 0.7024\n",
      "Epoch 97/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5961 - accuracy: 0.7188Epoch 97/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7076\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7076\n",
      "Epoch 98/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5729 - accuracy: 0.6562Epoch 98/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7073102 [=================>............] - ETA: 0s - loss: 0.5744 - accuracy: 0.\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5782 - accuracy: 0.7073\n",
      "Epoch 99/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7036\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7036\n",
      "Epoch 100/100\n",
      " 32/102 [========>.....................] - ETA: 0s - loss: 0.5817 - accuracy: 0.6963Epoch 100/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7017\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.7017\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5854 - accuracy: 0.6883\n",
      "26/26 [==============================] - 0s 1ms/step - loss: 0.5854 - accuracy: 0.6883\n",
      "[0.585399866104126, 0.6883435845375061]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69       407\n",
      "           1       0.69      0.68      0.69       408\n",
      "\n",
      "    accuracy                           0.69       815\n",
      "   macro avg       0.69      0.69      0.69       815\n",
      "weighted avg       0.69      0.69      0.69       815\n",
      "\n",
      "[0.585399866104126, 0.6883435845375061]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69       407\n",
      "           1       0.69      0.68      0.69       408\n",
      "\n",
      "    accuracy                           0.69       815\n",
      "   macro avg       0.69      0.69      0.69       815\n",
      "weighted avg       0.69      0.69      0.69       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e24f56",
   "metadata": {},
   "source": [
    "# Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "05453cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Over sampling\n",
      "Random Over sampling\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class_1_over=df_class_1.sample(count_class_0,replace=True)\n",
    "df_test_over=pd.concat([df_class_1_over,df_class_0],axis=0)\n",
    "print(\"Random Over sampling\")\n",
    "df_test_over.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8de6a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x=df_test_under.drop(\"Exited\",axis=1)\n",
    "y=df_test_under[\"Exited\"]\n",
    "X_train, X_test, y_train, y_test=train_test_split(x,y,test_size=0.2,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8de7144d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1630\n",
       "0    1629\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "1    1630\n",
       "0    1629\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "91e3a0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN(X_train, y_train, X_test, y_test, loss):\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(13, input_dim=12, activation='relu'),\n",
    "        keras.layers.Dense(10, activation='relu'),\n",
    "        keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    \n",
    "    model.fit(X_train, y_train, epochs=100)\n",
    "\n",
    "    print(model.evaluate(X_test, y_test))\n",
    "\n",
    "    y_preds = model.predict(X_test)\n",
    "    y_preds = np.round(y_preds)\n",
    "\n",
    "    print(\"Classification Report: \\n\", classification_report(y_test, y_preds))\n",
    "\n",
    "    return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "dbd57cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.6832 - accuracy: 0.5459\n",
      "102/102 [==============================] - 1s 2ms/step - loss: 0.6832 - accuracy: 0.5459\n",
      "Epoch 2/100\n",
      "  1/102 [..............................] - ETA: 1s - loss: 0.6906 - accuracy: 0.5000Epoch 2/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.5766\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.5766\n",
      "Epoch 3/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7404 - accuracy: 0.5625Epoch 3/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.6042\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6623 - accuracy: 0.6042\n",
      "Epoch 4/100\n",
      "  1/102 [..............................] - ETA: 1s - loss: 0.6273 - accuracy: 0.6562Epoch 4/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.6250\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.6250\n",
      "Epoch 5/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6201 - accuracy: 0.6875Epoch 5/100\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.6398102 [===>..........................] - ETA: 0s - loss:\n",
      "102/102 [==============================] - 0s 4ms/step - loss: 0.6320 - accuracy: 0.6398\n",
      "Epoch 6/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6087 - accuracy: 0.6875Epoch 6/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6573\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.6573\n",
      "Epoch 7/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5569 - accuracy: 0.7812Epoch 7/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6680\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6120 - accuracy: 0.6680\n",
      "Epoch 8/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6870 - accuracy: 0.6250Epoch 8/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6747\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.6040 - accuracy: 0.6747\n",
      "Epoch 9/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6740 - accuracy: 0.5625Epoch 9/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.6843\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5962 - accuracy: 0.6843\n",
      "Epoch 10/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5618 - accuracy: 0.6875Epoch 10/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.6876\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5968 - accuracy: 0.6876\n",
      "Epoch 11/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6137 - accuracy: 0.6250Epoch 11/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6836102 [======>.......................] - ETA: 0s - loss: 0.5977 - ac\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5933 - accuracy: 0.6836\n",
      "Epoch 12/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6476 - accuracy: 0.5938Epoch 12/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6861\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5923 - accuracy: 0.6861\n",
      "Epoch 13/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5861 - accuracy: 0.7500Epoch 13/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.6858\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.6858\n",
      "Epoch 14/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6595 - accuracy: 0.6562Epoch 14/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.6901\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.6901\n",
      "Epoch 15/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6946 - accuracy: 0.6562Epoch 15/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.6919\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5878 - accuracy: 0.6919\n",
      "Epoch 16/100\n",
      "Epoch 16/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.6935\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.6935\n",
      "Epoch 17/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4849 - accuracy: 0.8438Epoch 17/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.6956\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.6956\n",
      "Epoch 18/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5727 - accuracy: 0.6875Epoch 18/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.6910\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5891 - accuracy: 0.6910\n",
      "Epoch 19/100\n",
      "  1/102 [..............................] - ETA: 1s - loss: 0.5115 - accuracy: 0.8125Epoch 19/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.6956\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.6956\n",
      "Epoch 20/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7233 - accuracy: 0.5312Epoch 20/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.6984\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.6984\n",
      "Epoch 21/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5606 - accuracy: 0.6875Epoch 21/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.6971\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.6971\n",
      "Epoch 22/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5344 - accuracy: 0.7188Epoch 22/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.6950\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.6950\n",
      "Epoch 23/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4622 - accuracy: 0.8125Epoch 23/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.6978\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.6978\n",
      "Epoch 24/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5781 - accuracy: 0.7188Epoch 24/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.6968\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.6968\n",
      "Epoch 25/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5834 - accuracy: 0.7812Epoch 25/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.6984\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.6984\n",
      "Epoch 26/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6051 - accuracy: 0.6875Epoch 26/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.6993\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.6993\n",
      "Epoch 27/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4105 - accuracy: 0.8438Epoch 27/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7002\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7002\n",
      "Epoch 28/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5567 - accuracy: 0.7188Epoch 28/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.6975\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5837 - accuracy: 0.6975\n",
      "Epoch 29/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6462 - accuracy: 0.7500Epoch 29/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7005\n",
      "Epoch 30/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5618 - accuracy: 0.6250Epoch 30/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.6975\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5840 - accuracy: 0.6975\n",
      "Epoch 31/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6437 - accuracy: 0.6562Epoch 31/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7017\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7017\n",
      "Epoch 32/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6105 - accuracy: 0.6250Epoch 32/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7011\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7011\n",
      "Epoch 33/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6551 - accuracy: 0.6562Epoch 33/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.6978102 [===============>..............] - ETA: 0s - loss: 0.5837 - accura\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5834 - accuracy: 0.6978\n",
      "Epoch 34/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5898 - accuracy: 0.6875Epoch 34/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6965\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.6965\n",
      "Epoch 35/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5915 - accuracy: 0.6562Epoch 35/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.6993\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.6993\n",
      "Epoch 36/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6935 - accuracy: 0.5625Epoch 36/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7048\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7048\n",
      "Epoch 37/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6103 - accuracy: 0.7188Epoch 37/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7017\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7017\n",
      "Epoch 38/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6348 - accuracy: 0.5938Epoch 38/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7002\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7002\n",
      "Epoch 39/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6788 - accuracy: 0.5938Epoch 39/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6990\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6990\n",
      "Epoch 40/100\n",
      "Epoch 40/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.6975102 [..............................] - ETA: 0s - loss: 0.4786 \n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.6975\n",
      "Epoch 41/100\n",
      "  1/102 [..............................] - ETA: 1s - loss: 0.6161 - accuracy: 0.6875Epoch 41/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7036\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5827 - accuracy: 0.7036\n",
      "Epoch 42/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6142 - accuracy: 0.5938Epoch 42/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.7014\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5823 - accuracy: 0.7014\n",
      "Epoch 43/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5627 - accuracy: 0.7188Epoch 43/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.6984\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5831 - accuracy: 0.6984\n",
      "Epoch 44/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5382 - accuracy: 0.7500Epoch 44/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.6996\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5817 - accuracy: 0.6996\n",
      "Epoch 45/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6520 - accuracy: 0.7188Epoch 45/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7024\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5817 - accuracy: 0.7024\n",
      "Epoch 46/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5647 - accuracy: 0.7812Epoch 46/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7030\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7030\n",
      "Epoch 47/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7138 - accuracy: 0.5312Epoch 47/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7024\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7024\n",
      "Epoch 48/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4997 - accuracy: 0.6562Epoch 48/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7045\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7045\n",
      "Epoch 49/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5283 - accuracy: 0.7188Epoch 49/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6947\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6947\n",
      "Epoch 50/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5572 - accuracy: 0.7188Epoch 50/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.6987\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.6987\n",
      "Epoch 51/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5330 - accuracy: 0.7188Epoch 51/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7033\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7033\n",
      "Epoch 52/100\n",
      "Epoch 52/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7011\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5821 - accuracy: 0.7011\n",
      "Epoch 53/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6908 - accuracy: 0.5625Epoch 53/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6978\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.6978\n",
      "Epoch 54/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6952 - accuracy: 0.6562Epoch 54/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7042\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7042\n",
      "Epoch 55/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5424 - accuracy: 0.7812Epoch 55/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7008\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7008\n",
      "Epoch 56/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5776 - accuracy: 0.7188Epoch 56/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.6962\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.6962\n",
      "Epoch 57/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4784 - accuracy: 0.8750Epoch 57/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7079\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7079\n",
      "Epoch 58/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6337 - accuracy: 0.6875Epoch 58/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.6956\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5815 - accuracy: 0.6956\n",
      "Epoch 59/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6337 - accuracy: 0.6562Epoch 59/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.6984\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.6984\n",
      "Epoch 60/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6884 - accuracy: 0.6562Epoch 60/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7021\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5830 - accuracy: 0.7021\n",
      "Epoch 61/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4151 - accuracy: 0.8125Epoch 61/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.7002\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.7002\n",
      "Epoch 62/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7020 - accuracy: 0.5625Epoch 62/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7030\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.7030\n",
      "Epoch 63/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6270 - accuracy: 0.6875Epoch 63/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7030\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7030\n",
      "Epoch 64/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6016 - accuracy: 0.6875Epoch 64/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7008\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7008\n",
      "Epoch 65/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6800 - accuracy: 0.6875Epoch 65/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7048102 [==============================] - ETA: 0s - loss: 0.5812 - accuracy: 0.70\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7048\n",
      "Epoch 66/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7089 - accuracy: 0.5938Epoch 66/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7036\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7036\n",
      "Epoch 67/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5262 - accuracy: 0.7188Epoch 67/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.6999\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.6999\n",
      "Epoch 68/100\n",
      "Epoch 68/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7024\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7024\n",
      "Epoch 69/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5281 - accuracy: 0.7500Epoch 69/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7070\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.7070\n",
      "Epoch 70/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5554 - accuracy: 0.7812Epoch 70/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.70050s - loss: 0.5723 - accuracy: 0.7013 - ETA: 0s - loss: 0.5723 - ac\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7005\n",
      "Epoch 71/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5915 - accuracy: 0.7500Epoch 71/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7027\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7027\n",
      "Epoch 72/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5886 - accuracy: 0.7500Epoch 72/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7033\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5806 - accuracy: 0.7033\n",
      "Epoch 73/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6295 - accuracy: 0.7500Epoch 73/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7027\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5793 - accuracy: 0.7027\n",
      "Epoch 74/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5293 - accuracy: 0.6875Epoch 74/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7021\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7021\n",
      "Epoch 75/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5241 - accuracy: 0.7500Epoch 75/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7021\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7021\n",
      "Epoch 76/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6277 - accuracy: 0.6562Epoch 76/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.6981\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5807 - accuracy: 0.6981\n",
      "Epoch 77/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4814 - accuracy: 0.7812Epoch 77/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7017\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5812 - accuracy: 0.7017\n",
      "Epoch 78/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6488 - accuracy: 0.6875Epoch 78/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7033\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5803 - accuracy: 0.7033\n",
      "Epoch 79/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5740 - accuracy: 0.7812Epoch 79/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7042\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7042\n",
      "Epoch 80/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6013 - accuracy: 0.5938Epoch 80/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7024\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.7024\n",
      "Epoch 81/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6131 - accuracy: 0.6562Epoch 81/100\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7027\n",
      "102/102 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.7027\n",
      "Epoch 82/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5897 - accuracy: 0.6875Epoch 82/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7030\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7030\n",
      "Epoch 83/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6861 - accuracy: 0.5312Epoch 83/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7024\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7024\n",
      "Epoch 84/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6264 - accuracy: 0.5938Epoch 84/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7002\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7002\n",
      "Epoch 85/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5897 - accuracy: 0.6875Epoch 85/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7067\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5805 - accuracy: 0.7067\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/102 [..............................] - ETA: 0s - loss: 0.5253 - accuracy: 0.8438Epoch 86/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7024\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5795 - accuracy: 0.7024\n",
      "Epoch 87/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6640 - accuracy: 0.5625Epoch 87/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.7005\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5828 - accuracy: 0.7005\n",
      "Epoch 88/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7080 - accuracy: 0.6562Epoch 88/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7021\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5802 - accuracy: 0.7021\n",
      "Epoch 89/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4744 - accuracy: 0.7812Epoch 89/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7017\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5816 - accuracy: 0.7017\n",
      "Epoch 90/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5053 - accuracy: 0.7500Epoch 90/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7030\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7030\n",
      "Epoch 91/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6049 - accuracy: 0.6250Epoch 91/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7091\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7091\n",
      "Epoch 92/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6189 - accuracy: 0.7188Epoch 92/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7027\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7027\n",
      "Epoch 93/100Epoch 93/100\n",
      "  1/102 [..............................] - ETA: 1s - loss: 0.7502 - accuracy: 0.5000\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7054\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5814 - accuracy: 0.7054\n",
      "Epoch 94/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4996 - accuracy: 0.7188Epoch 94/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7033\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5829 - accuracy: 0.7033\n",
      "Epoch 95/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.5433 - accuracy: 0.7500Epoch 95/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.6996\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.6996\n",
      "Epoch 96/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6128 - accuracy: 0.6562Epoch 96/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7033\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5804 - accuracy: 0.7033\n",
      "Epoch 97/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6115 - accuracy: 0.6250Epoch 97/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.7057\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5809 - accuracy: 0.7057\n",
      "Epoch 98/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.6619 - accuracy: 0.6562Epoch 98/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7011\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5810 - accuracy: 0.7011\n",
      "Epoch 99/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.7358 - accuracy: 0.5000Epoch 99/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7060\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5789 - accuracy: 0.7060\n",
      "Epoch 100/100\n",
      "  1/102 [..............................] - ETA: 0s - loss: 0.4470 - accuracy: 0.7500Epoch 100/100\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.6999\n",
      "102/102 [==============================] - 0s 2ms/step - loss: 0.5811 - accuracy: 0.6999\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7080\n",
      "26/26 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7080\n",
      "[0.572230339050293, 0.707975447177887]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       408\n",
      "           1       0.71      0.70      0.71       407\n",
      "\n",
      "    accuracy                           0.71       815\n",
      "   macro avg       0.71      0.71      0.71       815\n",
      "weighted avg       0.71      0.71      0.71       815\n",
      "\n",
      "[0.572230339050293, 0.707975447177887]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71       408\n",
      "           1       0.71      0.70      0.71       407\n",
      "\n",
      "    accuracy                           0.71       815\n",
      "   macro avg       0.71      0.71      0.71       815\n",
      "weighted avg       0.71      0.71      0.71       815\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9a3840",
   "metadata": {},
   "source": [
    "## SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "449d5666",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited', axis='columns')\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0f07a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2be31b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote=SMOTE(sampling_strategy='minority')\n",
    "X_sm, y_sm = smote.fit_resample(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "55837a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    7963\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sm.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e757f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=15, stratify=y_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f6385537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.7154 - accuracy: 0.6252\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.7154 - accuracy: 0.6252\n",
      "Epoch 2/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.5539 - accuracy: 0.7500Epoch 2/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5671 - accuracy: 0.7178\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5671 - accuracy: 0.7178\n",
      "Epoch 3/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.5709 - accuracy: 0.6875Epoch 3/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5276 - accuracy: 0.7423\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5276 - accuracy: 0.7423\n",
      "Epoch 4/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.7196 - accuracy: 0.5625Epoch 4/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7435\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5192 - accuracy: 0.7435\n",
      "Epoch 5/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4332 - accuracy: 0.8438Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5155 - accuracy: 0.7436\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5155 - accuracy: 0.7436\n",
      "Epoch 6/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4708 - accuracy: 0.8125Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5119 - accuracy: 0.7463\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5119 - accuracy: 0.7463\n",
      "Epoch 7/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.5639 - accuracy: 0.7188Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5110 - accuracy: 0.7486\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5110 - accuracy: 0.7486\n",
      "Epoch 8/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.5999 - accuracy: 0.6562Epoch 8/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5112 - accuracy: 0.7449\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5112 - accuracy: 0.7449\n",
      "Epoch 9/100\n",
      "  1/399 [..............................] - ETA: 6s - loss: 0.5170 - accuracy: 0.6562Epoch 9/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5084 - accuracy: 0.7465\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5084 - accuracy: 0.7465\n",
      "Epoch 10/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.5761 - accuracy: 0.6562Epoch 10/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5041 - accuracy: 0.7491\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.5041 - accuracy: 0.7491\n",
      "Epoch 11/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.6302 - accuracy: 0.6250Epoch 11/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5030 - accuracy: 0.7505\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5030 - accuracy: 0.7505\n",
      "Epoch 12/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.5605 - accuracy: 0.7812Epoch 12/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5010 - accuracy: 0.7508\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.5010 - accuracy: 0.7508\n",
      "Epoch 13/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.5267 - accuracy: 0.7188Epoch 13/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4979 - accuracy: 0.7516\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4979 - accuracy: 0.7516\n",
      "Epoch 14/100\n",
      "  1/399 [..............................] - ETA: 5s - loss: 0.5900 - accuracy: 0.7188Epoch 14/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4967 - accuracy: 0.7512\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4967 - accuracy: 0.7512\n",
      "Epoch 15/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.5756 - accuracy: 0.7812Epoch 15/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4937 - accuracy: 0.7540\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4937 - accuracy: 0.7540\n",
      "Epoch 16/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4010 - accuracy: 0.8125Epoch 16/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4943 - accuracy: 0.7529\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4943 - accuracy: 0.7529\n",
      "Epoch 17/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.3904 - accuracy: 0.8750Epoch 17/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4909 - accuracy: 0.7550\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4909 - accuracy: 0.7550\n",
      "Epoch 18/100\n",
      "  1/399 [..............................] - ETA: 6s - loss: 0.5748 - accuracy: 0.7188Epoch 18/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4902 - accuracy: 0.7552\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4902 - accuracy: 0.7552\n",
      "Epoch 19/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.5126 - accuracy: 0.7500Epoch 19/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4879 - accuracy: 0.7589\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4879 - accuracy: 0.7589\n",
      "Epoch 20/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4990 - accuracy: 0.7188Epoch 20/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.7586\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.7586\n",
      "Epoch 21/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4324 - accuracy: 0.7500Epoch 21/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4835 - accuracy: 0.7602\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4835 - accuracy: 0.7602\n",
      "Epoch 22/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.5451 - accuracy: 0.7188Epoch 22/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.7589399 [>................\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4833 - accuracy: 0.7589\n",
      "Epoch 23/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.5579 - accuracy: 0.7188Epoch 23/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4777 - accuracy: 0.7621\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4777 - accuracy: 0.7621\n",
      "Epoch 24/100\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.7630\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4765 - accuracy: 0.7630\n",
      "Epoch 25/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4201 - accuracy: 0.7812Epoch 25/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4744 - accuracy: 0.7632\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4744 - accuracy: 0.7632\n",
      "Epoch 26/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4552 - accuracy: 0.7812Epoch 26/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4730 - accuracy: 0.7656\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4730 - accuracy: 0.7656\n",
      "Epoch 27/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.3722 - accuracy: 0.8438Epoch 27/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4714 - accuracy: 0.7692\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4714 - accuracy: 0.7692\n",
      "Epoch 28/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.3361 - accuracy: 0.9375Epoch 28/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4699 - accuracy: 0.7676\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4699 - accuracy: 0.7676\n",
      "Epoch 29/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4769 - accuracy: 0.8125Epoch 29/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.7706\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4675 - accuracy: 0.7706\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/399 [..............................] - ETA: 0s - loss: 0.5907 - accuracy: 0.7188Epoch 30/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4683 - accuracy: 0.7714\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4683 - accuracy: 0.7714\n",
      "Epoch 31/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.5524 - accuracy: 0.6875Epoch 31/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4626 - accuracy: 0.7740\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4626 - accuracy: 0.7740\n",
      "Epoch 32/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4869 - accuracy: 0.7188Epoch 32/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4632 - accuracy: 0.7743\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4632 - accuracy: 0.7743\n",
      "Epoch 33/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4793 - accuracy: 0.7812Epoch 33/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4616 - accuracy: 0.7728\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4616 - accuracy: 0.7728\n",
      "Epoch 34/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.7102 - accuracy: 0.7188Epoch 34/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4610 - accuracy: 0.7745\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4610 - accuracy: 0.7745\n",
      "Epoch 35/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4150 - accuracy: 0.7812Epoch 35/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.7759\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4627 - accuracy: 0.7759\n",
      "Epoch 36/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4079 - accuracy: 0.7812Epoch 36/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4598 - accuracy: 0.7768\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4598 - accuracy: 0.7768\n",
      "Epoch 37/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.3496 - accuracy: 0.8438Epoch 37/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4575 - accuracy: 0.7791\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4575 - accuracy: 0.7791\n",
      "Epoch 38/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.2588 - accuracy: 0.9688Epoch 38/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4556 - accuracy: 0.7786\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4556 - accuracy: 0.7786\n",
      "Epoch 39/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.5053 - accuracy: 0.7188Epoch 39/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4548 - accuracy: 0.7823\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4548 - accuracy: 0.7823\n",
      "Epoch 40/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.3541 - accuracy: 0.8750Epoch 40/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4555 - accuracy: 0.7809\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4555 - accuracy: 0.7809\n",
      "Epoch 41/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4761 - accuracy: 0.7188Epoch 41/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4535 - accuracy: 0.7830\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4535 - accuracy: 0.7830\n",
      "Epoch 42/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.5179 - accuracy: 0.7500Epoch 42/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4528 - accuracy: 0.7805\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4528 - accuracy: 0.7805\n",
      "Epoch 43/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.5312 - accuracy: 0.7812Epoch 43/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4504 - accuracy: 0.7824\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4504 - accuracy: 0.7824\n",
      "Epoch 44/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4713 - accuracy: 0.7500Epoch 44/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.7834\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.7834\n",
      "Epoch 45/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4954 - accuracy: 0.8125Epoch 45/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.7825\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.7825\n",
      "Epoch 46/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4270 - accuracy: 0.7500Epoch 46/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4505 - accuracy: 0.7849\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4505 - accuracy: 0.7849\n",
      "Epoch 47/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4596 - accuracy: 0.7188Epoch 47/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.78260s - loss: 0.4499 - accuracy: 0.7845 - ETA: 0s - loss: 0.4499 \n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4515 - accuracy: 0.7826\n",
      "Epoch 48/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4629 - accuracy: 0.7188Epoch 48/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.7868399 [==>........................\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4488 - accuracy: 0.7868\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4475 - accuracy: 0.7858\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4475 - accuracy: 0.7858\n",
      "Epoch 50/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4460 - accuracy: 0.8438Epoch 50/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4491 - accuracy: 0.7865\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4491 - accuracy: 0.7865\n",
      "Epoch 51/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4061 - accuracy: 0.8750Epoch 51/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4477 - accuracy: 0.7861\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4477 - accuracy: 0.7861\n",
      "Epoch 52/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4204 - accuracy: 0.8125Epoch 52/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4466 - accuracy: 0.7867\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4466 - accuracy: 0.7867\n",
      "Epoch 53/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4009 - accuracy: 0.8438Epoch 53/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4456 - accuracy: 0.7849\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4456 - accuracy: 0.7849\n",
      "Epoch 54/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.2929 - accuracy: 0.8750Epoch 54/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4441 - accuracy: 0.7890\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4441 - accuracy: 0.7890\n",
      "Epoch 55/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.6324 - accuracy: 0.7188Epoch 55/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4441 - accuracy: 0.7882\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4441 - accuracy: 0.7882\n",
      "Epoch 56/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4679 - accuracy: 0.8438Epoch 56/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4403 - accuracy: 0.7910399 [>................\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4403 - accuracy: 0.7910\n",
      "Epoch 57/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.6635 - accuracy: 0.6875Epoch 57/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4392 - accuracy: 0.7940\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4392 - accuracy: 0.7940\n",
      "Epoch 58/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.2913 - accuracy: 0.8438Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4394 - accuracy: 0.7924\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4394 - accuracy: 0.7924\n",
      "Epoch 59/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.5111 - accuracy: 0.6875Epoch 59/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4378 - accuracy: 0.7920\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4378 - accuracy: 0.7920\n",
      "Epoch 60/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.5402 - accuracy: 0.7188Epoch 60/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4367 - accuracy: 0.7932\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4367 - accuracy: 0.7932\n",
      "Epoch 61/100\n",
      "  1/399 [..............................] - ETA: 1s - loss: 0.4369 - accuracy: 0.7812Epoch 61/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.7975\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4351 - accuracy: 0.7975\n",
      "Epoch 62/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.3834 - accuracy: 0.8438Epoch 62/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4330 - accuracy: 0.8005\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4330 - accuracy: 0.8005\n",
      "Epoch 63/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.2719 - accuracy: 0.8750Epoch 63/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.8006399 [>....................\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4316 - accuracy: 0.8006\n",
      "Epoch 64/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.6091 - accuracy: 0.6250Epoch 64/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4306 - accuracy: 0.80030s - loss: 0.4286 - accuracy: 0.8011 - ETA: 0s - loss: 0.4286 - accura\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4306 - accuracy: 0.8003\n",
      "Epoch 65/100\n",
      "Epoch 65/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4307 - accuracy: 0.8024\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4307 - accuracy: 0.8024\n",
      "Epoch 66/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.3420 - accuracy: 0.8438Epoch 66/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4264 - accuracy: 0.8020\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4264 - accuracy: 0.8020\n",
      "Epoch 67/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4349 - accuracy: 0.8125Epoch 67/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4265 - accuracy: 0.80210s - loss: 0.4258 - accuracy: 0.8026 - ETA: 0s - l\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4265 - accuracy: 0.8021\n",
      "Epoch 68/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4489 - accuracy: 0.8438Epoch 68/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4221 - accuracy: 0.8053\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4221 - accuracy: 0.8053\n",
      "Epoch 69/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.3662 - accuracy: 0.7812Epoch 69/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4222 - accuracy: 0.8059\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4222 - accuracy: 0.8059\n",
      "Epoch 70/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4724 - accuracy: 0.7812Epoch 70/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4204 - accuracy: 0.8086\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4204 - accuracy: 0.8086\n",
      "Epoch 71/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4210 - accuracy: 0.7812Epoch 71/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4185 - accuracy: 0.8074\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4185 - accuracy: 0.8074\n",
      "Epoch 72/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.3694 - accuracy: 0.8438Epoch 72/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4144 - accuracy: 0.8086\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4144 - accuracy: 0.8086\n",
      "Epoch 73/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.3279 - accuracy: 0.8750Epoch 73/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4120 - accuracy: 0.8089\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4120 - accuracy: 0.8089\n",
      "Epoch 74/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.3420 - accuracy: 0.7812Epoch 74/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4040 - accuracy: 0.8119\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4040 - accuracy: 0.8119\n",
      "Epoch 75/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.5600 - accuracy: 0.7812Epoch 75/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4024 - accuracy: 0.8148\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4024 - accuracy: 0.8148\n",
      "Epoch 76/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4639 - accuracy: 0.7500Epoch 76/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4022 - accuracy: 0.8135\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4022 - accuracy: 0.8135\n",
      "Epoch 77/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4368 - accuracy: 0.7812Epoch 77/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8122\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.4002 - accuracy: 0.8122\n",
      "Epoch 78/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4433 - accuracy: 0.7812Epoch 78/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3986 - accuracy: 0.8169\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3986 - accuracy: 0.8169\n",
      "Epoch 79/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4825 - accuracy: 0.7500Epoch 79/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3985 - accuracy: 0.8144\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3985 - accuracy: 0.8144\n",
      "Epoch 80/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.2820 - accuracy: 0.8438Epoch 80/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3972 - accuracy: 0.8115\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3972 - accuracy: 0.8115\n",
      "Epoch 81/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.5324 - accuracy: 0.6875Epoch 81/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3973 - accuracy: 0.8151\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3973 - accuracy: 0.8151\n",
      "Epoch 82/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.3039 - accuracy: 0.8438Epoch 82/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3976 - accuracy: 0.8151\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3976 - accuracy: 0.8151\n",
      "Epoch 83/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.2502 - accuracy: 0.9062Epoch 83/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3973 - accuracy: 0.8128\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3973 - accuracy: 0.8128\n",
      "Epoch 84/100Epoch 84/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.3219 - accuracy: 0.9062\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3958 - accuracy: 0.81730s - loss: 0.3970 - accuracy: 0.8170 - ETA: 0s - loss: 0.3970 - accuracy: 0.8240/399 [=================>............] - ETA: 0s - loss:\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3958 - accuracy: 0.8173\n",
      "Epoch 85/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4727 - accuracy: 0.8125Epoch 85/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3954 - accuracy: 0.8166\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3954 - accuracy: 0.8166\n",
      "Epoch 86/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.3294 - accuracy: 0.8750Epoch 86/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8182\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3951 - accuracy: 0.8182\n",
      "Epoch 87/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.2899 - accuracy: 0.9375Epoch 87/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3936 - accuracy: 0.8200\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3936 - accuracy: 0.8200\n",
      "Epoch 88/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.5731 - accuracy: 0.7500Epoch 88/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3948 - accuracy: 0.8176\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3948 - accuracy: 0.8176\n",
      "Epoch 89/100\n",
      "  1/399 [..............................] - ETA: 2s - loss: 0.5538 - accuracy: 0.8125Epoch 89/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8165\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8165\n",
      "Epoch 90/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4520 - accuracy: 0.7812Epoch 90/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3929 - accuracy: 0.8177\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3929 - accuracy: 0.8177\n",
      "Epoch 91/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.3184 - accuracy: 0.8438Epoch 91/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3962 - accuracy: 0.8158\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3962 - accuracy: 0.8158\n",
      "Epoch 92/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.3874 - accuracy: 0.8750Epoch 92/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3939 - accuracy: 0.8143\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3939 - accuracy: 0.8143\n",
      "Epoch 93/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4179 - accuracy: 0.8125Epoch 93/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3943 - accuracy: 0.8151\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3943 - accuracy: 0.8151\n",
      "Epoch 94/100\n",
      "  1/399 [..............................] - ETA: 1s - loss: 0.2837 - accuracy: 0.9062Epoch 94/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3940 - accuracy: 0.8164\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3940 - accuracy: 0.8164\n",
      "Epoch 95/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.3291 - accuracy: 0.9375Epoch 95/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3944 - accuracy: 0.8176\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3944 - accuracy: 0.8176\n",
      "Epoch 96/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.2936 - accuracy: 0.8438Epoch 96/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3955 - accuracy: 0.8159\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3955 - accuracy: 0.8159\n",
      "Epoch 97/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.4380 - accuracy: 0.7812Epoch 97/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3943 - accuracy: 0.8165\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3943 - accuracy: 0.8165\n",
      "Epoch 98/100\n",
      "  1/399 [..............................] - ETA: 0s - loss: 0.2780 - accuracy: 0.8750Epoch 98/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3938 - accuracy: 0.8187\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3938 - accuracy: 0.8187\n",
      "Epoch 99/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.4298 - accuracy: 0.7812Epoch 99/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8143\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3950 - accuracy: 0.8143\n",
      "Epoch 100/100\n",
      "  1/399 [..............................] - ETA: 3s - loss: 0.2564 - accuracy: 0.8750Epoch 100/100\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3942 - accuracy: 0.8187\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.3942 - accuracy: 0.8187\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8280\n",
      "100/100 [==============================] - 0s 2ms/step - loss: 0.3823 - accuracy: 0.8280\n",
      "[0.3822558522224426, 0.8279975056648254]\n",
      "[0.3822558522224426, 0.8279975056648254]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1593\n",
      "           1       0.84      0.82      0.83      1593\n",
      "\n",
      "    accuracy                           0.83      3186\n",
      "   macro avg       0.83      0.83      0.83      3186\n",
      "weighted avg       0.83      0.83      0.83      3186\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83      1593\n",
      "           1       0.84      0.82      0.83      1593\n",
      "\n",
      "    accuracy                           0.83      3186\n",
      "   macro avg       0.83      0.83      0.83      3186\n",
      "weighted avg       0.83      0.83      0.83      3186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5515cd5",
   "metadata": {},
   "source": [
    "## Ensemble with undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c7559b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Exited.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6af84934",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Exited', axis='columns')\n",
    "y = df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "050dd16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, random_state=15, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c52b695",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = X_train.copy()\n",
    "df2['Exited'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "954e2049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Geography_France</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5710</th>\n",
       "      <td>0.856</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>0.554265</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.339721</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3745</th>\n",
       "      <td>0.852</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>0.371163</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.980432</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5429</th>\n",
       "      <td>0.664</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.325318</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>0.648</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>6</td>\n",
       "      <td>0.426077</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.010339</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8967</th>\n",
       "      <td>0.970</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417230</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Gender  Age  Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
       "5710        0.856       1   34       5  0.554265              2          0   \n",
       "3745        0.852       0   37       1  0.371163              2          1   \n",
       "5429        0.664       0   48       7  0.000000              2          1   \n",
       "551         0.648       1   47       6  0.426077              1          1   \n",
       "8967        0.970       1   25       7  0.000000              2          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Geography_France  Geography_Germany  \\\n",
       "5710               0         0.339721                 1                  0   \n",
       "3745               1         0.980432                 0                  1   \n",
       "5429               0         0.325318                 1                  0   \n",
       "551                1         0.010339                 0                  1   \n",
       "8967               1         0.417230                 1                  0   \n",
       "\n",
       "      Geography_Spain  Exited  \n",
       "5710                0       0  \n",
       "3745                0       0  \n",
       "5429                0       0  \n",
       "551                 0       1  \n",
       "8967                0       0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "433973b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_class0 = df2[df2.Exited == 0]\n",
    "df2_class1 = df2[df2.Exited == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b7a87bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "\n",
    "    X_train = df_train.drop('Exited', axis='columns')\n",
    "    y_train = df_train.Exited\n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d4365f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "98/98 [==============================] - 1s 2ms/step - loss: 1.3898 - accuracy: 0.5373\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6766 - accuracy: 0.5805: 0s - loss: 0.6779 - accuracy: 0.57\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6128\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6451\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.6560\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6103 - accuracy: 0.6822\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6062 - accuracy: 0.6742\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.6826\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.6854\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5972 - accuracy: 0.6893\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.7011\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5948 - accuracy: 0.6918\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5918 - accuracy: 0.6851\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.6925\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5921 - accuracy: 0.6976\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.7008\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5869 - accuracy: 0.7008\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5890 - accuracy: 0.6922\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.6979\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.6954\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5910 - accuracy: 0.6864\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5892 - accuracy: 0.6899\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6950\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5871 - accuracy: 0.6938\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5968 - accuracy: 0.6870\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.6998\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5922 - accuracy: 0.6835\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.6989\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5936 - accuracy: 0.6931\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.6947\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5927 - accuracy: 0.6998\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.7014\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5902 - accuracy: 0.6976\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.7030\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.6950\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.7014\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5973 - accuracy: 0.6838\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.7069\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5901 - accuracy: 0.6934\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5876 - accuracy: 0.6966\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5886 - accuracy: 0.7053\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5858 - accuracy: 0.7043\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5860 - accuracy: 0.6947\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7021\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.7005\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.6976\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.6989\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.7037\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5879 - accuracy: 0.6989\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5926 - accuracy: 0.6899\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5845 - accuracy: 0.7024\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5846 - accuracy: 0.7034\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5909 - accuracy: 0.6970\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - ETA: 0s - loss: 0.5813 - accuracy: 0.70 - 0s 2ms/step - loss: 0.5822 - accuracy: 0.7050\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5868 - accuracy: 0.6986\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5819 - accuracy: 0.7037\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5870 - accuracy: 0.6973\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7018\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7002\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.6918\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.7024\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5928 - accuracy: 0.6893\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.6922\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5831 - accuracy: 0.6979\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5846 - accuracy: 0.6954\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.6960\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6877\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5832 - accuracy: 0.7062\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5849 - accuracy: 0.7014\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5885 - accuracy: 0.7021\n",
      "Epoch 71/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5913 - accuracy: 0.6896\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5906 - accuracy: 0.6950: 0s - loss: 0.5906 - accuracy: 0.69\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5873 - accuracy: 0.6998\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7021\n",
      "Epoch 75/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.6957\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.6995\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5861 - accuracy: 0.6970\n",
      "Epoch 78/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5852 - accuracy: 0.7050\n",
      "Epoch 79/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.6957\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5854 - accuracy: 0.7091\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.6995\n",
      "Epoch 82/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5880 - accuracy: 0.6966\n",
      "Epoch 83/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7021\n",
      "Epoch 84/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5908 - accuracy: 0.6947\n",
      "Epoch 85/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.7043\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5887 - accuracy: 0.7011\n",
      "Epoch 87/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5889 - accuracy: 0.7008\n",
      "Epoch 88/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.6954\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.7034\n",
      "Epoch 90/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5896 - accuracy: 0.6973\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7069\n",
      "Epoch 92/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5863 - accuracy: 0.7011\n",
      "Epoch 93/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.6950\n",
      "Epoch 94/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5833 - accuracy: 0.7037\n",
      "Epoch 95/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5893 - accuracy: 0.6925\n",
      "Epoch 96/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.6934\n",
      "Epoch 97/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5865 - accuracy: 0.7066\n",
      "Epoch 98/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5874 - accuracy: 0.6963\n",
      "Epoch 99/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.7021\n",
      "Epoch 100/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5839 - accuracy: 0.6963\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.7490\n",
      "[0.5221912860870361, 0.7490000128746033]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.84      1593\n",
      "           1       0.41      0.55      0.47       407\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.64      0.68      0.65      2000\n",
      "weighted avg       0.78      0.75      0.76      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_class0, df2_class1, 0, 1495)\n",
    "\n",
    "y_pred1 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "434de699",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "98/98 [==============================] - 1s 2ms/step - loss: 0.6530 - accuracy: 0.6118\n",
      "Epoch 2/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.6538\n",
      "Epoch 3/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.6088 - accuracy: 0.6621\n",
      "Epoch 4/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5987 - accuracy: 0.6768\n",
      "Epoch 5/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5920 - accuracy: 0.6819\n",
      "Epoch 6/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5877 - accuracy: 0.6829\n",
      "Epoch 7/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5841 - accuracy: 0.6909\n",
      "Epoch 8/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.6893\n",
      "Epoch 9/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5756 - accuracy: 0.7078\n",
      "Epoch 10/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5734 - accuracy: 0.7050\n",
      "Epoch 11/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5673 - accuracy: 0.7114\n",
      "Epoch 12/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7101\n",
      "Epoch 13/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5620 - accuracy: 0.7165\n",
      "Epoch 14/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5555 - accuracy: 0.7242\n",
      "Epoch 15/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5527 - accuracy: 0.7245\n",
      "Epoch 16/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5489 - accuracy: 0.7274\n",
      "Epoch 17/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5438 - accuracy: 0.7357\n",
      "Epoch 18/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5425 - accuracy: 0.7293\n",
      "Epoch 19/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5381 - accuracy: 0.7360\n",
      "Epoch 20/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5345 - accuracy: 0.7325: 0s - loss: 0.5425 - accuracy\n",
      "Epoch 21/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5303 - accuracy: 0.7357\n",
      "Epoch 22/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7379\n",
      "Epoch 23/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7450\n",
      "Epoch 24/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5220 - accuracy: 0.7472\n",
      "Epoch 25/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5218 - accuracy: 0.7446\n",
      "Epoch 26/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.7427\n",
      "Epoch 27/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.7507\n",
      "Epoch 28/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5186 - accuracy: 0.7507\n",
      "Epoch 29/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7453\n",
      "Epoch 30/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.7475\n",
      "Epoch 31/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.7552\n",
      "Epoch 32/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7517\n",
      "Epoch 33/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.7482\n",
      "Epoch 34/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.7546\n",
      "Epoch 35/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.7510\n",
      "Epoch 36/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5056 - accuracy: 0.7488: 0s - loss: 0.5050 - accuracy: 0.75\n",
      "Epoch 37/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7552\n",
      "Epoch 38/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7488\n",
      "Epoch 39/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7555\n",
      "Epoch 40/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.7523\n",
      "Epoch 41/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.7485\n",
      "Epoch 42/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7469\n",
      "Epoch 43/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.7504\n",
      "Epoch 44/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.7574\n",
      "Epoch 45/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.7539\n",
      "Epoch 46/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7597\n",
      "Epoch 47/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.7536\n",
      "Epoch 48/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.7533\n",
      "Epoch 49/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7523\n",
      "Epoch 50/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.7562\n",
      "Epoch 51/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7645\n",
      "Epoch 52/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7542\n",
      "Epoch 53/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7587\n",
      "Epoch 54/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.7613\n",
      "Epoch 55/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7507\n",
      "Epoch 56/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7562\n",
      "Epoch 57/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.7578\n",
      "Epoch 58/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.7642\n",
      "Epoch 59/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7597\n",
      "Epoch 60/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.7581\n",
      "Epoch 61/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7552\n",
      "Epoch 62/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.7469\n",
      "Epoch 63/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.7613\n",
      "Epoch 64/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.7622\n",
      "Epoch 65/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.7517\n",
      "Epoch 66/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.7600\n",
      "Epoch 67/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.7552\n",
      "Epoch 68/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.7574\n",
      "Epoch 69/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.7600\n",
      "Epoch 70/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.7584\n",
      "Epoch 71/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.7571\n",
      "Epoch 72/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.7549\n",
      "Epoch 73/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.7546\n",
      "Epoch 74/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.7597\n",
      "Epoch 75/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7549\n",
      "Epoch 76/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.7616\n",
      "Epoch 77/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.7552: 0s - loss: 0.4974 - accuracy: \n",
      "Epoch 78/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.7626\n",
      "Epoch 79/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.7629\n",
      "Epoch 80/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.7578\n",
      "Epoch 81/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7600\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7571\n",
      "Epoch 83/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.7632\n",
      "Epoch 84/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.7594\n",
      "Epoch 85/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.7549\n",
      "Epoch 86/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.7590\n",
      "Epoch 87/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.7638\n",
      "Epoch 88/100\n",
      "98/98 [==============================] - 0s 3ms/step - loss: 0.4941 - accuracy: 0.7581\n",
      "Epoch 89/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7606\n",
      "Epoch 90/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.7629\n",
      "Epoch 91/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.7632\n",
      "Epoch 92/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7658\n",
      "Epoch 93/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.7568\n",
      "Epoch 94/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7629\n",
      "Epoch 95/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.7632\n",
      "Epoch 96/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.7642\n",
      "Epoch 97/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7619\n",
      "Epoch 98/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.7626\n",
      "Epoch 99/100\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7616\n",
      "Epoch 100/100\n",
      "98/98 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.7571\n",
      "63/63 [==============================] - 0s 3ms/step - loss: 0.5128 - accuracy: 0.7455\n",
      "[0.5128224492073059, 0.7455000281333923]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.74      0.82      1593\n",
      "           1       0.43      0.78      0.55       407\n",
      "\n",
      "    accuracy                           0.75      2000\n",
      "   macro avg       0.68      0.76      0.69      2000\n",
      "weighted avg       0.83      0.75      0.77      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_class0, df2_class1, 1495, 2990)\n",
    "\n",
    "y_pred2 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "70878e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "87/87 [==============================] - 1s 2ms/step - loss: 1.7892 - accuracy: 0.6007\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.6563\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6722\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.6021 - accuracy: 0.6823\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5919 - accuracy: 0.6884\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5856 - accuracy: 0.6953\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.7137\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5718 - accuracy: 0.7199\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5674 - accuracy: 0.7181\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7209\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 0.5626 - accuracy: 0.7159\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 0.5607 - accuracy: 0.7242\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7289\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7274\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7260\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7332\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7365\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5520 - accuracy: 0.7303\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7260\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 0s 1ms/step - loss: 0.5510 - accuracy: 0.7354\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7314\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7307\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7339\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7264\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7253\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7343\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7264\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7332\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7339\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7350\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7292\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7285\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7325\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7321\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7303\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7307\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7256\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 0.5492 - accuracy: 0.7357\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7325\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7300\n",
      "Epoch 41/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7267\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7314\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7289\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7296\n",
      "Epoch 45/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7386\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7245\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7347\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7365\n",
      "Epoch 49/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7339\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7372\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7350\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7321\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7292\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7343\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7368\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 0.5500 - accuracy: 0.7318\n",
      "Epoch 57/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7332\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7329\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7296\n",
      "Epoch 60/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7321\n",
      "Epoch 61/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7231\n",
      "Epoch 62/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7318\n",
      "Epoch 63/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7314\n",
      "Epoch 64/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7354\n",
      "Epoch 65/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7282\n",
      "Epoch 66/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7307\n",
      "Epoch 67/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7314\n",
      "Epoch 68/100\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7394\n",
      "Epoch 69/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7354\n",
      "Epoch 70/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7368\n",
      "Epoch 71/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7357\n",
      "Epoch 72/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7336\n",
      "Epoch 73/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7339\n",
      "Epoch 74/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7336\n",
      "Epoch 75/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7332\n",
      "Epoch 76/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7329\n",
      "Epoch 77/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7357\n",
      "Epoch 78/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7368\n",
      "Epoch 79/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5473 - accuracy: 0.7361\n",
      "Epoch 80/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7397\n",
      "Epoch 81/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7354\n",
      "Epoch 82/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7318\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7386\n",
      "Epoch 84/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7314\n",
      "Epoch 85/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7357\n",
      "Epoch 86/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7354\n",
      "Epoch 87/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7332\n",
      "Epoch 88/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7314\n",
      "Epoch 89/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7375\n",
      "Epoch 90/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7300\n",
      "Epoch 91/100\n",
      "87/87 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7401\n",
      "Epoch 92/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7365\n",
      "Epoch 93/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7307\n",
      "Epoch 94/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7361\n",
      "Epoch 95/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7365\n",
      "Epoch 96/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7343\n",
      "Epoch 97/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7343\n",
      "Epoch 98/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7372\n",
      "Epoch 99/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7325\n",
      "Epoch 100/100\n",
      "87/87 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7375\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 0.7435 - accuracy: 0.5920\n",
      "[0.7435420155525208, 0.5920000076293945]\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.53      0.68      1593\n",
      "           1       0.31      0.82      0.45       407\n",
      "\n",
      "    accuracy                           0.59      2000\n",
      "   macro avg       0.62      0.68      0.56      2000\n",
      "weighted avg       0.80      0.59      0.63      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_train_batch(df2_class0, df2_class1, 2990, 4130)\n",
    "\n",
    "y_pred3 = ANN(X_train, y_train, X_test, y_test, 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "11c55154",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = y_pred1.copy()\n",
    "for i in range(len(y_pred1)):\n",
    "    n_ones = y_pred1[i] + y_pred2[i] + y_pred3[i]\n",
    "    if n_ones > 1:\n",
    "        y_pred_final[i] = 1\n",
    "    else:\n",
    "        y_pred_final[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e3f5859c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.72      0.80      1593\n",
      "           1       0.40      0.73      0.51       407\n",
      "\n",
      "    accuracy                           0.72      2000\n",
      "   macro avg       0.65      0.72      0.66      2000\n",
      "weighted avg       0.81      0.72      0.74      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cl_rep = classification_report(y_test, y_pred_final)\n",
    "print(cl_rep)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
